{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad4183f",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with U-Net\n",
    "\n",
    "This notebook implements a complete semantic segmentation model using PyTorch. We'll implement a U-Net architecture, which is particularly effective for semantic segmentation tasks. The model will be trained on a sample dataset to segment images into different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2460147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# For downloading sample data\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 128)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 256)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 512)\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(512, 1024)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.conv1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv4 = DoubleConv(128, 64)\n",
    "        \n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x5)\n",
    "        x = self.conv1(torch.cat([x4, x], dim=1))\n",
    "        x = self.up2(x)\n",
    "        x = self.conv2(torch.cat([x3, x], dim=1))\n",
    "        x = self.up3(x)\n",
    "        x = self.conv3(torch.cat([x2, x], dim=1))\n",
    "        x = self.up4(x)\n",
    "        x = self.conv4(torch.cat([x1, x], dim=1))\n",
    "        \n",
    "        return self.outc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58992ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace('.jpg', '_mask.png'))\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')  # Convert mask to grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}')\n",
    "\n",
    "def visualize_prediction(model, image, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        output = model(image)\n",
    "        pred_mask = torch.argmax(output, dim=1)\n",
    "        \n",
    "        # Convert tensors to numpy arrays for visualization\n",
    "        image = image.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        pred_mask = pred_mask.cpu().squeeze().numpy()\n",
    "        \n",
    "        # Plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title('Original Image')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(pred_mask, cmap='gray')\n",
    "        ax2.set_title('Predicted Mask')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Example of how to use the model (commented out as we need actual data)\n",
    "'''\n",
    "# Create dataset and dataloader\n",
    "dataset = SegmentationDataset(\n",
    "    image_dir='path/to/images',\n",
    "    mask_dir='path/to/masks',\n",
    "    transform=transform\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, device)\n",
    "\n",
    "# Visualize a prediction\n",
    "sample_image, _ = dataset[0]\n",
    "visualize_prediction(model, sample_image, device)\n",
    "'''\n",
    "\n",
    "# USE COLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460020c",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. This implementation provides a complete U-Net model for semantic segmentation.\n",
    "2. The model can handle any number of input channels and output classes.\n",
    "3. To use this model with your own data:\n",
    "   - Organize your images and corresponding masks in separate directories\n",
    "   - Create a SegmentationDataset instance with your directories\n",
    "   - Use the provided training utilities to train the model\n",
    "   - Use the visualization function to see the results\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The implemented U-Net architecture consists of:\n",
    "- Encoder path with 4 downsampling blocks\n",
    "- Decoder path with 4 upsampling blocks\n",
    "- Skip connections between encoder and decoder\n",
    "- Double convolution blocks with batch normalization\n",
    "\n",
    "### Requirements\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision pillow matplotlib numpy\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
